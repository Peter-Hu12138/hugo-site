+++
date = '2025-11-29T02:39:04-05:00'
draft = false
title = 'CSC236: Introduction to Theory of Computation'
categories = ['Computer Science']
tags = ['Theory']
+++
{{< katex >}}
I am still on my way to finish the notes for CSC236.
## Introduction
Computer Science is about problem-solving: understanding, modelling, and solving problems. How do computer scientists ensure what they do is correct? Logic and math are all you need, and of all the math humans have explored, discrete mathmatics is the most relevant to the core of computer science - logic, language, and formal representation of structures. Thus, naturally, a lot of contents in the course concern topics in discrete mathematics if not all.

## Induction
### Simple Induction (a.k.a. Weak Induction)
### Complete Induction (a.k.a Strong Induction)
### Structural Induction
### Well Ordering Principle

## Algorithm Correctness

Meaning of correctness:

`
If the precondition is met, then the algorithm will terminate free of error and meet post condition.
`

### Recursive Algorithm Correctness

What follows are conditions to check for recursive algorithm correctness, the principle goes:

Assume precondition is met, proving the following suffices as proof of the correctness of the algorithm:

1. Valid recursively (Decreasing size): Size is a function of input whose output is the a natural, and we need to prove size is strictly decreasing in consecutive recursive calls by showing each function delegates to recursive calls with a value whose size is smaller.
2. Valid calls:  all the calls are valid (satisfying preconditions), non-recursive ones and recursive ones.
3. Correct return value (postcondition): Assuming recursive calls are correct (if we supplement the calls with correct input values, they will terminate and return correct return values free of error), we prove the function returns correct return values.

Why is it correct? The principle relies on Well Ordering Principle and induction under the hood.

We can justify termination with "valid recursively", if a size function has a codomain of naturals and decreases on consecutive recursive calls always, then any call to the algorithm would generate a decreasing sequence of naturals formed by the sizes of recursive calls on the call stack. Since all decreasing sequences of naturals are finite, which is a corollary of Well Ordering Principle (WOP), the sequence of finite calls terminates.

For valid calls and correct return values, we based correctness on correctness of recursive calls, but why can we assume recursive calls are correct and take what follows as a sufficient proof for the correctness of the entire algorithm. Isn't that circular reasoning? It isn't because we are not assuming \\(P(n)\\) is correct and proving \\(P(n)\\) is correct, what we do is essentially assuming \\(P(k)\\) is correct and proving \\(P(n)\\) is correct for some \\(k < n\\) with respect to the size function. 

This resembles and in fact depends on induction, I will first demonstrate one proof with complete induction. To start, let's assume inputs are of the set \\(C\\) and define \\(P\\) be the predicate that \\(\forall c \in C, P(c) \\) denotes the algorithm is correct on input \\(c\\). The ultimate goal is to prove \\(\forall c \in C, P(c)\\). To use complete induction, we need a size function to measure inputs; by valid recursively, it could be assumed w.l.o.g. there exists \\(size: C \to \mathbb{N}\\).

After setting up, we get this guy with aid of size function: \\(\forall n \in \mathbb{N}, \forall c \in C, n = size(c) \implies P(c)\\); note that the truth of this statement implies the truth of \\(\forall c \in C, P(c)\\), you can verify by selecting an arbitrary \\(c \in C\\), and realize \\(size(c) \in \mathhbb{N}\\). Therefore it suffices to prove the longer one with complete induction:

Let \\(n \in \mathbb{N}\\) and assume \\(\forall k \in \mathbb{N}, k < n \implies \forall c \in C, k = size(c) \implies P(c)\\) (I.H.) Since we proved any recursive call made has a smaller size (valid recursively), by I.H., we can work with these recursive calls as if they are correct as they descend to smaller sizes by "valid recursively" and conclude with complete induction that the algorithm is correct on every input from \\(C\\).

> **Note:** Intuively, we can understand it as if we are trying to find a metric - the size function with a codomain of naturals - such that the recursive algorithm is always calling (or delegating) itself with smaller inputs with respect to the metric.

Similarly, a structural induction approach could make a proof but perhaps cleaner for this proof omits a definition of a size function but requires a construction of a recurrence definition of the input size. It is then needed that we prove \\(P\\) on the base cases and then on the constructor cases, which could naturally match the writeup of the algorithm.

### Iterative Algorithm Correctness

Proving that iterative algorithms are correct is similar, relying on inductive thinking, with differences in how repetitions are handled: iterative algorithms don't call themselves on smaller cases but base their correctness off what was left after previous iterations - a.k.a. Loop Invariants.

Usually, a iterative algorthm correctness has the following components:

1. A decreasing loop variant: define a size function whose codomain is naturals and prove this function is strictly decreasing on iterations.


## Mathematical Recurrence Formula and Runtime analysis

### Master's Theorem

#### Intuitive "Proof" of Master's Theorem

## Finite Automata, Regular Expression, and Regular Language

### Myhill-Nerode Theorem & Irregular Language